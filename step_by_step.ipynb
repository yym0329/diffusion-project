{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# package import\n",
    "\n",
    "from data_pack import DataSetDefinition\n",
    "import utils_cpu\n",
    "import utils_gpu\n",
    "\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_def = DataSetDefinition(\n",
    "    processed_dir_suffix=\"128_v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/processed'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_def.processed_data_root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2_split = dataset_def.step2_dict_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = step2_split[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "easy_dict = EasyDict(train_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_path': './data/processed/train/images/obj_01_car/obj_01_car_004_CC7.png',\n",
       " 'mask_path': './data/processed/train/masks/obj_01_car/obj_01_car_CC7.png',\n",
       " 'viewpoint_id': 'CC7',\n",
       " 'lighting_condition_id': '004',\n",
       " 'image_id': 'obj_01_car',\n",
       " 'output_dir': './data/processed/128_v1/train/hints',\n",
       " 'fov': None,\n",
       " 'mask_threshold': 0.25,\n",
       " 'env_map': './data/generate_light_gt_sg/hdrs/004.hdr',\n",
       " 'pls': [[0, 0, 0]],\n",
       " 'use_gpu_for_rendering': True,\n",
       " 'resolution': 128}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering radiance hints for ./data/processed/train/images/obj_01_car/obj_01_car_004_CC7.png with viewpoint CC7 and lighting condition 004\n",
      "Radiance hints already rendered to ./data/processed/128_v1/train/hints/obj_01_car/CC7/004/hint00_diffuse.png\n",
      "Radiance hints already rendered to ./data/processed/128_v1/train/hints/obj_01_car/CC7/004/hint00_ggx0.05.png\n",
      "Radiance hints already rendered to ./data/processed/128_v1/train/hints/obj_01_car/CC7/004/hint00_ggx0.13.png\n",
      "Radiance hints already rendered to ./data/processed/128_v1/train/hints/obj_01_car/CC7/004/hint00_ggx0.34.png\n",
      ">> Inference with model on 2 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " init edge (0*,1*) score=19.84580421447754\n",
      " init loss = 0.0017114599468186498\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'im_depthmaps', 'im_poses', 'im_focals']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 69.31it/s, lr=1.27413e-06 loss=0.00125564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh reconstructed with fov: 33.81208801269531\n",
      "Data are loaded, start creating Blender stuff\n",
      "glTF import finished in 0.25s\n",
      "> \u001b[0;32m/data2/code/diffusion-project/DiLightNet/demo/render_hints.py\u001b[0m(73)\u001b[0;36mconfigure_blender\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     72 \u001b[0;31m            \u001b[0;31m# Enable the GPU device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 73 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'CUDA'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering RGB and Hints: 100%|██████████| 4/4 [00:02<00:00,  1.40it/s]\n",
      "Rendering Hints: 100%|██████████| 1/1 [00:02<00:00,  2.86s/it]\n"
     ]
    }
   ],
   "source": [
    "radiance_result = utils_gpu.elem_generate_hint(train_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory structure -> list of data\n",
    "\n",
    "step1_datadict_train_list: List[Dict[str, str]] = []\n",
    "step1_datadict_eval_list: List[Dict[str, str]] = []\n",
    "\n",
    "for each_class_name in dataset_def.class_name_list:\n",
    "    for each_view_point in dataset_def.view_point_list:\n",
    "        for each_light_condition in dataset_def.light_condition_list:\n",
    "\n",
    "            image_path = DataSetDefinition.get_image_path(\n",
    "                data_root_dir=dataset_def.raw_data_root_dir,\n",
    "                class_name=each_class_name,\n",
    "                light_condition=each_light_condition,\n",
    "                view_point=each_view_point,\n",
    "            )\n",
    "            mask_path = DataSetDefinition.get_mask_path(\n",
    "                data_root_dir=dataset_def.raw_data_root_dir,\n",
    "                class_name=each_class_name,\n",
    "                view_point=each_view_point,\n",
    "            )\n",
    "\n",
    "            parsed_name = DataSetDefinition.get_image_path(\n",
    "                data_root_dir=dataset_def.raw_data_root_dir,\n",
    "                class_name=each_class_name,\n",
    "                light_condition=each_light_condition,\n",
    "                view_point=each_view_point,\n",
    "                parsed=True,\n",
    "            )\n",
    "\n",
    "            if parsed_name in dataset_def.eval_split:\n",
    "                step1_datadict_eval_list.append(\n",
    "                    {\n",
    "                        \"key\": f\"{each_class_name}_{each_light_condition}_{each_view_point}\",\n",
    "                        \"image_path\": image_path,\n",
    "                        \"mask_path\": mask_path,\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                step1_datadict_train_list.append(\n",
    "                    {\n",
    "                        \"key\": f\"{each_class_name}_{each_light_condition}_          {each_view_point}\",\n",
    "                        \"image_path\": image_path,\n",
    "                        \"mask_path\": mask_path,\n",
    "                    }\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
