{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "import random \n",
    "import os \n",
    "import glob\n",
    "import argparse \n",
    "\n",
    "\n",
    "# DO NOT modify the hyperparameters\n",
    "RESIZE_H, RESIZE_W = 100, 100\n",
    "H, W = 128, 128\n",
    "\n",
    "\n",
    "# Use this function to preprocess data\n",
    "def center_crop_img(tgt_img_path, mask_img_path):\n",
    "    tgt_img = Image.open(tgt_img_path).convert(\"RGB\")\n",
    "    np_tgt_img = np.array(tgt_img)\n",
    "\n",
    "    # mask is processed as [0, 255] value\n",
    "    mask_img = Image.open(mask_img_path).convert(\"RGB\") # Foreground mask\n",
    "    # For some of the masks are given as [0, 255]\n",
    "    if np.array(mask_img).max() > 1:\n",
    "        np_mask_img = np.array(mask_img)\n",
    "    else:\n",
    "        np_mask_img = np.array(mask_img) * 255\n",
    "    assert np_mask_img.max() <= 255 and np_mask_img.min() >= 0, f\"{np_mask_img.min()}, {np_mask_img.max()}\"\n",
    "    np_tgt_img[np_mask_img == 0] = 255\n",
    "\n",
    "    # Crop image using bbox\n",
    "    y, x, r = np.where(np_mask_img == 255) # Get bbox using the mask\n",
    "    x1, x2, y1, y2 = x.min(), x.max(), y.min(), y.max()\n",
    "\n",
    "    crop_img = Image.fromarray(np_tgt_img).crop(\n",
    "        (x1, y1, x2, y2)\n",
    "    )\n",
    "    cropped_mask = Image.fromarray(np_mask_img).crop(\n",
    "        (x1, y1, x2, y2)\n",
    "    )\n",
    "    w = x2 - x1 \n",
    "    assert w > 0, f\"{x2} - {x1} = {w}\"\n",
    "    h = y2 - y1 \n",
    "    assert h > 0, f\"{y2} - {y1} = {h}\"\n",
    "\n",
    "    # Resize image with respect to max length \n",
    "    max_length = max(w, h)\n",
    "    ratio = RESIZE_W / max_length\n",
    "    resized_w, resized_h = round(w * ratio), round(h * ratio) # Avoid float error\n",
    "    assert resized_h == RESIZE_H or resized_w == RESIZE_W\n",
    "\n",
    "    resized_img = crop_img.resize(\n",
    "        (resized_w, resized_h)\n",
    "    )\n",
    "    resized_object_mask = cropped_mask.resize(\n",
    "        (resized_w, resized_h)\n",
    "    )\n",
    "    img_canvas = Image.new(\"RGB\", (H, W), (255, 255, 255))\n",
    "    mask_canvas = Image.new(\"RGB\", (H, W), (0, 0, 0))\n",
    "    pos_w, pos_h = resized_w - W, resized_h - H\n",
    "    \n",
    "    pos_w = abs(pos_w) // 2\n",
    "    pos_h = abs(pos_h) // 2\n",
    "    assert pos_w + resized_w <= W and pos_h + resized_h <= H\n",
    "\n",
    "    img_canvas.paste(\n",
    "        resized_img, (pos_w, pos_h)\n",
    "    )\n",
    "    mask_canvas.paste(\n",
    "        resized_object_mask, (pos_w, pos_h)\n",
    "    )\n",
    "\n",
    "    return img_canvas, mask_canvas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = 'metadata.json'\n",
    "with open(json_file) as f:\n",
    "    data = json.load(f)\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouput_dir = 'data/center_cropped'\n",
    "os.makedirs(ouput_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert object Mask to 3 channel mask.\n",
    "\n",
    "\n",
    "Directory Structure:\n",
    "\n",
    "```\n",
    "data/\n",
    "    images/\n",
    "      obj_28_metal_bucket/\n",
    "        obj_28_metal_bucket_002_CA2.png\n",
    "        obj_28_metal_bucket_003_CA2.png  \n",
    "        ...\n",
    "    masks/\n",
    "      obj_28_metal_bucket/\n",
    "        mask_obj_28_metal_bucket_CA2.png\n",
    "      ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "def process_image(k, output_dir, data):\n",
    "  tgt_img_path = data[k]['tgt_img_path']\n",
    "  mask_img_path = data[k]['mask_path']\n",
    "  img, mask = center_crop_img(tgt_img_path, mask_img_path)\n",
    "\n",
    "  img_name = k + '.png'\n",
    "  # key example: 'obj_28_metal_bucket_010_NA3'\n",
    "  object_name = k[:-8]\n",
    "  viewpoint_id = k[-3:]\n",
    "  \n",
    "  image_dir = os.path.join(output_dir, 'images', object_name)\n",
    "  if not os.path.exists(image_dir):\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "  output_img_path = os.path.join(image_dir, img_name)\n",
    "  \n",
    "  mask_dir = os.path.join(output_dir, 'masks', object_name)\n",
    "  if not os.path.exists(mask_dir):\n",
    "    os.makedirs(mask_dir, exist_ok=True)\n",
    "  \n",
    "  mask_file_name = object_name +'_' + viewpoint_id + '.png'\n",
    "  output_mask_path = os.path.join(mask_dir, mask_file_name)\n",
    "  \n",
    "  img.save(output_img_path)\n",
    "  mask.save(output_mask_path)\n",
    "  print(f\"Saved {output_img_path}\")\n",
    "  print(f\"Saved {output_mask_path}\")\n",
    "  \n",
    "\n",
    "# Create a pool of workers\n",
    "def process_images(json_path, output_dir):\n",
    "  with open(json_path) as f:\n",
    "      data = json.load(f)\n",
    "  os.makedirs(output_dir, exist_ok=True)\n",
    "  \n",
    "  with Pool() as pool:\n",
    "      for _ in tqdm(pool.imap_unordered(partial(process_image, data=data, output_dir=output_dir), data.keys()), total=len(data)):\n",
    "          pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images(json_file, 'center_cropped_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert object Mask to 3 channel mask.\n",
    "\n",
    "\n",
    "Directory Structure:\n",
    "\n",
    "```\n",
    "data/\n",
    "    images/\n",
    "      obj_28_metal_bucket/\n",
    "        obj_28_metal_bucket_002_CA2.png\n",
    "        obj_28_metal_bucket_003_CA2.png  \n",
    "        ...\n",
    "    masks/\n",
    "      obj_28_metal_bucket/\n",
    "        mask_obj_28_metal_bucket_CA2.png\n",
    "      ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make jsonl file, which contains the path to the images and masks\n",
    "def make_jsonl(output_path, data_dir):\n",
    "  with open(output_path, 'w') as f:\n",
    "    images_dir = os.path.join(data_dir, 'images')\n",
    "    masks_dir = os.path.join(data_dir, 'masks')\n",
    "\n",
    "    for object_name in os.listdir(images_dir):\n",
    "      for image_name in os.listdir(os.path.join(images_dir, object_name)):\n",
    "        image_path = os.path.join(images_dir, object_name, image_name)\n",
    "        mask_name = image_name[:-11] + image_name[-7:]\n",
    "        mask_path = os.path.join(masks_dir, object_name, mask_name)\n",
    "        f.write(json.dumps({'image_path': image_path, 'mask_path': mask_path}) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_jsonl('center_cropped_2.jsonl', 'center_cropped_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask_json_path = 'center_cropped_2.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import simple_parsing\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    img: str  # Path to the image, to generate hints for.\n",
    "    seed: int = 3407  # Seed for the generation\n",
    "    fov: Optional[float] = None  # Field of view for the mesh reconstruction, none for auto estimation from the image\n",
    "\n",
    "    mask_path: Optional[str] = None  # Path to the mask for the image\n",
    "    use_sam: bool = True  # Use SAM for background removal\n",
    "    mask_threshold: float = 25.  # Mask threshold for foreground object extraction\n",
    "    \n",
    "    power: float = 1200.  # Power of the point light\n",
    "    use_gpu_for_rendering: bool = True  # Use GPU for radiance hints rendering\n",
    "\n",
    "    pl_x: float = 1.  # X position of the point light\n",
    "    pl_y: float = 1.  # Y position of the point light\n",
    "    pl_z: float = 1.  # Z position of the point light\n",
    "    \n",
    "\n",
    "def generate_hint(img, seed = 3407, fov = None, mask_path = None, use_sam = True, mask_threshold = 25., power = 1200., \n",
    "                  use_gpu_for_rendering = True, pl_x = 1., pl_y = 1., pl_z = 1., output_dir = 'radiance_hints'):\n",
    "    args = Args(img=img, seed=seed, fov=fov, mask_path=mask_path, use_sam=use_sam, mask_threshold=mask_threshold, power=power,\n",
    "                use_gpu_for_rendering=use_gpu_for_rendering, pl_x=pl_x, pl_y=pl_y, pl_z=pl_z)\n",
    "    \n",
    "    from DiLightNet.demo.mesh_recon import mesh_reconstruction\n",
    "    from DiLightNet.demo.relighting_gen import relighting_gen\n",
    "    from DiLightNet.demo.render_hints import render_hint_images, render_bg_images\n",
    "    from DiLightNet.demo.rm_bg import rm_bg\n",
    "    \n",
    "    # Load input image and generate/load mask\n",
    "    input_image = imageio.v3.imread(args.img)\n",
    "    input_image = cv2.resize(input_image, (512, 512))\n",
    "    \n",
    "    if args.mask_path:\n",
    "        mask = imageio.v3.imread(args.mask_path)\n",
    "        if mask.ndim == 3:\n",
    "            mask = mask[..., -1]\n",
    "        mask = cv2.resize(mask, (512, 512))\n",
    "    else:\n",
    "        _, mask = rm_bg(input_image, use_sam=args.use_sam)\n",
    "    mask = mask[..., None].repeat(3, axis=-1)\n",
    "    \n",
    "    # Render radiance hints\n",
    "    pls = [(\n",
    "        args.pl_x,\n",
    "        args.pl_y,\n",
    "        args.pl_z\n",
    "    ) ]\n",
    "\n",
    "    # cache middle results\n",
    "    img_id = os.path.basename(args.img).split(\".\")[0]\n",
    "    lighting_id = f\"pl-{args.pl_x}-{args.pl_y}-{args.pl_z}-{args.power}\"\n",
    "    output_folder = os.path.join(output_dir, img_id, lighting_id)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    # check if the radiance hints are already rendered and full\n",
    "    \n",
    "    print(f\"Rendering radiance hints\")\n",
    "    # Mesh reconstruction and fov estimation for hints rendering\n",
    "    fov = args.fov\n",
    "    mesh, fov = mesh_reconstruction(input_image, mask, False, fov, args.mask_threshold)\n",
    "    print(f\"Mesh reconstructed with fov: {fov}\")\n",
    "    render_hint_images(mesh, fov, pls, args.power, output_folder=output_folder, use_gpu=args.use_gpu_for_rendering)\n",
    "    print(f\"Radiance hints rendered to {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(img_mask_json_path) as f:\n",
    "    # load json file as a list of dict\n",
    "    data = [json.loads(line) for line in f]\n",
    "    for d in tqdm(data):\n",
    "        generate_hint(d['image_path'], mask_path=d['mask_path'], output_dir='radiance_hints')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
