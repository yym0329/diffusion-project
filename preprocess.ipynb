{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "To make a training dataset, we need such things:\n",
    "\n",
    "1. Ground Truth relighted images\n",
    "2. Radiance hints for (1) images\n",
    "3. Provisional Images for (1) images\n",
    "4. generated caption ofr (1) images, using BLIP2 model, for the brightened image.\n",
    "4. jsonl file that contains the information of (1) and (2) images\n",
    "\n",
    "The jsonl file should have the following format:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"image\": \"/absolute/path/to/your/file/view_0/white_pl_0/gt.png\",\n",
    "  \"hint\": [\n",
    "    \"/absolute/path/to/your/file/view_0/white_pl_0/gt_diffuse.png\",\n",
    "    \"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.05.png\"\n",
    "    \"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.13.png\"\n",
    "    \"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.34.png\"\n",
    "  ],\n",
    "  \"ref\": [\n",
    "    \"/absolute/path/to/your/file/view_0/white_pl_1/gt.png\",\n",
    "    \"/absolute/path/to/your/file/view_0/env_0/gt.png\",\n",
    "    \"/absolute/path/to/your/file/view_0/env_1/gt.png\",\n",
    "    \"...\"\n",
    "  ],\n",
    "  \"text\": \"some text description generated by BLIP2\"\n",
    "}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "import random \n",
    "import os \n",
    "import glob\n",
    "import argparse \n",
    "\n",
    "\n",
    "# DO NOT modify the hyperparameters\n",
    "RESIZE_H, RESIZE_W = 100, 100\n",
    "H, W = 128, 128\n",
    "\n",
    "\n",
    "# Use this function to preprocess data\n",
    "def center_crop_img(tgt_img_path, mask_img_path):\n",
    "\t\"\"\"\n",
    "\tPreprocess the image and mask to center crop and resize to 128x128\n",
    "\n",
    "\tArgs:\n",
    "\t\ttgt_img_path (str): Path to the target image\n",
    "\t\tmask_img_path (str): Path to the mask image\n",
    "\n",
    "\tReturns:\n",
    "\t\t(img_canvas, mask_canvas): Tuple of PIL images\n",
    "\t\"\"\"\n",
    "\ttgt_img = Image.open(tgt_img_path).convert(\"RGB\")\n",
    "\tnp_tgt_img = np.array(tgt_img)\n",
    "\n",
    "\t# mask is processed as [0, 255] value\n",
    "\tmask_img = Image.open(mask_img_path).convert(\"RGB\") # Foreground mask\n",
    "\t# For some of the masks are given as [0, 255]\n",
    "\tif np.array(mask_img).max() > 1:\n",
    "\t\tnp_mask_img = np.array(mask_img)\n",
    "\telse:\n",
    "\t\tnp_mask_img = np.array(mask_img) * 255\n",
    "\tassert np_mask_img.max() <= 255 and np_mask_img.min() >= 0, f\"{np_mask_img.min()}, {np_mask_img.max()}\"\n",
    "\tnp_tgt_img[np_mask_img == 0] = 255\n",
    "\n",
    "\t# Crop image using bbox\n",
    "\ty, x, r = np.where(np_mask_img == 255) # Get bbox using the mask\n",
    "\tx1, x2, y1, y2 = x.min(), x.max(), y.min(), y.max()\n",
    "\n",
    "\tcrop_img = Image.fromarray(np_tgt_img).crop(\n",
    "\t\t(x1, y1, x2, y2)\n",
    "\t)\n",
    "\tcropped_mask = Image.fromarray(np_mask_img).crop(\n",
    "\t\t(x1, y1, x2, y2)\n",
    "\t)\n",
    "\tw = x2 - x1 \n",
    "\tassert w > 0, f\"{x2} - {x1} = {w}\"\n",
    "\th = y2 - y1 \n",
    "\tassert h > 0, f\"{y2} - {y1} = {h}\"\n",
    "\n",
    "\t# Resize image with respect to max length \n",
    "\tmax_length = max(w, h)\n",
    "\tratio = RESIZE_W / max_length\n",
    "\tresized_w, resized_h = round(w * ratio), round(h * ratio) # Avoid float error\n",
    "\tassert resized_h == RESIZE_H or resized_w == RESIZE_W\n",
    "\n",
    "\tresized_img = crop_img.resize(\n",
    "\t\t(resized_w, resized_h)\n",
    "\t)\n",
    "\tresized_object_mask = cropped_mask.resize(\n",
    "\t\t(resized_w, resized_h)\n",
    "\t)\n",
    "\timg_canvas = Image.new(\"RGB\", (H, W), (255, 255, 255))\n",
    "\tmask_canvas = Image.new(\"RGB\", (H, W), (0, 0, 0))\n",
    "\tpos_w, pos_h = resized_w - W, resized_h - H\n",
    "\t\n",
    "\tpos_w = abs(pos_w) // 2\n",
    "\tpos_h = abs(pos_h) // 2\n",
    "\tassert pos_w + resized_w <= W and pos_h + resized_h <= H\n",
    "\n",
    "\timg_canvas.paste(\n",
    "\t\tresized_img, (pos_w, pos_h)\n",
    "\t)\n",
    "\tmask_canvas.paste(\n",
    "\t\tresized_object_mask, (pos_w, pos_h)\n",
    "\t)\n",
    "\n",
    "\treturn img_canvas, mask_canvas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert object Mask to 3 channel mask.\n",
    "\n",
    "\n",
    "Directory Structure:\n",
    "\n",
    "```plaintext\n",
    "data/\n",
    "\t\timages/\n",
    "\t\t\tobj_28_metal_bucket/\n",
    "\t\t\t\tobj_28_metal_bucket_002_CA2.png\n",
    "\t\t\t\tobj_28_metal_bucket_003_CA2.png  \n",
    "\t\t\t\t...\n",
    "\t\tmasks/\n",
    "\t\t\tobj_28_metal_bucket/\n",
    "\t\t\t\tmask_obj_28_metal_bucket_CA2.png\n",
    "\t\t\t...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "# Make jsonl file, which contains the path to the images and masks\n",
    "def make_jsonl(output_path, data_dir):\n",
    "\t\"\"\"\n",
    "\tMake a jsonl file that contains the path to the images and masks.\n",
    "\tThe jsonl file should have the following format:\n",
    "\t\n",
    "\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\"}\n",
    "\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\"}\n",
    "\n",
    "\tArgs:\n",
    "\t\toutput_path (str): path to the output jsonl file.\n",
    "\t\tdata_dir (str): path to the data directory.\n",
    "\t\"\"\"\n",
    "\twith open(output_path, 'w') as f:\n",
    "\t\timages_dir = os.path.join(data_dir, 'images')\n",
    "\t\tmasks_dir = os.path.join(data_dir, 'masks')\n",
    "\n",
    "\t\tfor object_name in os.listdir(images_dir):\n",
    "\t\t\tfor image_name in os.listdir(os.path.join(images_dir, object_name)):\n",
    "\t\t\t\timage_path = os.path.join(images_dir, object_name, image_name)\n",
    "\t\t\t\tmask_name = image_name[:-11] + image_name[-7:]\n",
    "\t\t\t\tmask_path = os.path.join(masks_dir, object_name, mask_name)\n",
    "\t\t\t\tf.write(json.dumps({'image_path': image_path, 'mask_path': mask_path}) + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "def process_image(k, output_dir, data):\n",
    "\t\"\"\"\n",
    "\tcrop the object image given the mask. and save the cropped image and mask to the output directory.\n",
    "\n",
    "\tArgs:\n",
    "\t\tk (str): key of the data.\n",
    "\t\toutput_dir (str): output directory.\n",
    "\t\tdata (dict): data dictionary. data[k] = {tgt_img_path: str, mask_path: str}, \n",
    "\t\twhere tgt_img_path is the path to the target image and mask_path is the \n",
    "\t\tpath to the mask image.\n",
    "\t\"\"\"\n",
    "\ttgt_img_path = data[k]['tgt_img_path']\n",
    "\tmask_img_path = data[k]['mask_path']\n",
    "\timg, mask = center_crop_img(tgt_img_path, mask_img_path)\n",
    "\n",
    "\timg_name = k + '.png'\n",
    "\t# key example: 'obj_28_metal_bucket_010_NA3'\n",
    "\tobject_name = k[:-8]\n",
    "\tviewpoint_id = k[-3:]\n",
    "\t\n",
    "\timage_dir = os.path.join(output_dir, 'images', object_name)\n",
    "\tif not os.path.exists(image_dir):\n",
    "\t\tos.makedirs(image_dir, exist_ok=True)\n",
    "\toutput_img_path = os.path.join(image_dir, img_name)\n",
    "\t\n",
    "\tmask_dir = os.path.join(output_dir, 'masks', object_name)\n",
    "\tif not os.path.exists(mask_dir):\n",
    "\t\tos.makedirs(mask_dir, exist_ok=True)\n",
    "\t\n",
    "\tmask_file_name = object_name +'_' + viewpoint_id + '.png'\n",
    "\toutput_mask_path = os.path.join(mask_dir, mask_file_name)\n",
    "\t\n",
    "\timg.save(output_img_path)\n",
    "\tmask.save(output_mask_path)\n",
    "\tprint(f\"Saved {output_img_path}\")\n",
    "\tprint(f\"Saved {output_mask_path}\")\n",
    "\t\n",
    "\n",
    "# Create a pool of workers\n",
    "def process_images(json_path, output_dir):\n",
    "\t\"\"\"\n",
    "\tProcess all images in the json file and save the cropped images and masks to the output directory.\n",
    "\tAnd make a jsonl file for metadata, named 'img_mask_map.jsonl' in the output directory.\n",
    "\tthe input json file should have the following format:\n",
    "\t{\n",
    "\t\t\"obj_1\": {\"tgt_img_path\": \"path/to/target/image\", \"mask_path\": \"path/to/mask/image\"},\n",
    "\t\t\"obj_2\": {\"tgt_img_path\": \"path/to/target/image\", \"mask_path\": \"path/to/mask/image\"},\n",
    "\t\t...\n",
    "\t}\n",
    "\tArgs:\n",
    "\t\tjson_path (str): path to the json file.\n",
    "\t\toutput_dir (str): output directory.\n",
    "\t\"\"\"\n",
    "\twith open(json_path) as f:\n",
    "\t\t\tdata = json.load(f)\n",
    "\tos.makedirs(output_dir, exist_ok=True)\n",
    "\t\n",
    "\twith Pool() as pool:\n",
    "\t\t\tfor _ in tqdm(pool.imap_unordered(partial(process_image, data=data, \n",
    "\t\t\t\t\t\t\t\t\t\t\t output_dir=output_dir), data.keys()),\n",
    "\t\t\t\t\t\t\t\t\t\t\t   total=len(data)):\n",
    "\t\t\t\t\tpass\n",
    "\t\n",
    "\t# make jsonl file for metadata\n",
    "\tmake_jsonl(os.path.join(output_dir, 'img_mask_map.jsonl'), output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Images and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = 'data/metadata.json'\n",
    "with open(json_file) as f:\n",
    "\tdata = json.load(f)\n",
    "\tprint(len(data))\n",
    "\n",
    "ouput_dir = 'data/center_cropped_test'\n",
    "os.makedirs(ouput_dir, exist_ok=True)\n",
    "\n",
    "process_images(json_file, 'center_cropped_2_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask_json_path = 'data/center_cropped/img_mask_map.jsonl'\n",
    "with open(img_mask_json_path) as f:\n",
    "\tdata = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import json\n",
    "import imageio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import simple_parsing\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "\t\timg: str  # Path to the image, to generate hints for.\n",
    "\t\tseed: int = 3407  # Seed for the generation\n",
    "\t\tfov: Optional[float] = None  # Field of view for the mesh reconstruction, none for auto estimation from the image\n",
    "\n",
    "\t\tmask_path: Optional[str] = None  # Path to the mask for the image\n",
    "\t\tuse_sam: bool = True  # Use SAM for background removal\n",
    "\t\tmask_threshold: float = 25.  # Mask threshold for foreground object extraction\n",
    "\t\t\n",
    "\t\tpower: float = 1200.  # Power of the point light\n",
    "\t\tuse_gpu_for_rendering: bool = True  # Use GPU for radiance hints rendering\n",
    "\n",
    "\t\tpl_x: float = 1.  # X position of the point light\n",
    "\t\tpl_y: float = 1.  # Y position of the point light\n",
    "\t\tpl_z: float = 1.  # Z position of the point light\n",
    "\n",
    "\t\tenv_map_path: Optional[str] = None  # Path to the environment map\n",
    "\t\t\n",
    "\n",
    "def generate_hint(img, seed = 3407, fov = None, mask_path = None, use_sam = True, mask_threshold = 25., power = 1200., \n",
    "\t\t\t\t\t\t\t\t\tuse_gpu_for_rendering = True, pl_x = 1., pl_y = 1., pl_z = 1., output_dir = 'radiance_hints'):\n",
    "\t\targs = Args(img=img, seed=seed, fov=fov, mask_path=mask_path, use_sam=use_sam, mask_threshold=mask_threshold, power=power,\n",
    "\t\t\t\t\t\t\t\tuse_gpu_for_rendering=use_gpu_for_rendering, pl_x=pl_x, pl_y=pl_y, pl_z=pl_z)\n",
    "\t\t\n",
    "\t\tfrom DiLightNet.demo.mesh_recon import mesh_reconstruction\n",
    "\t\tfrom DiLightNet.demo.relighting_gen import relighting_gen\n",
    "\t\tfrom DiLightNet.demo.render_hints import render_hint_images, render_bg_images\n",
    "\t\tfrom DiLightNet.demo.rm_bg import rm_bg\n",
    "\t\t\n",
    "\t\t# Load input image and generate/load mask\n",
    "\t\tinput_image = imageio.v3.imread(args.img)\n",
    "\t\tinput_image = cv2.resize(input_image, (512, 512))\n",
    "\t\t\n",
    "\t\tif args.mask_path:\n",
    "\t\t\t\tmask = imageio.v3.imread(args.mask_path)\n",
    "\t\t\t\tif mask.ndim == 3:\n",
    "\t\t\t\t\t\tmask = mask[..., -1]\n",
    "\t\t\t\tmask = cv2.resize(mask, (512, 512))\n",
    "\t\telse:\n",
    "\t\t\t\t_, mask = rm_bg(input_image, use_sam=args.use_sam)\n",
    "\t\tmask = mask[..., None].repeat(3, axis=-1)\n",
    "\t\t\n",
    "\t\t# Render radiance hints\n",
    "\t\tpls = [(\n",
    "\t\t\t\targs.pl_x,\n",
    "\t\t\t\targs.pl_y,\n",
    "\t\t\t\targs.pl_z\n",
    "\t\t) ]\n",
    "\n",
    "\t\t# cache middle results\n",
    "\t\timg_id = os.path.basename(args.img).split(\".\")[0]\n",
    "\t\tlighting_id = f\"pl-{args.pl_x}-{args.pl_y}-{args.pl_z}-{args.power}\"\n",
    "\t\toutput_folder = os.path.join(output_dir, img_id, lighting_id)\n",
    "\t\tos.makedirs(output_folder, exist_ok=True)\n",
    "\t\t# check if the radiance hints are already rendered and full\n",
    "\t\t\n",
    "\t\tprint(f\"Rendering radiance hints\")\n",
    "\t\t# Mesh reconstruction and fov estimation for hints rendering\n",
    "\t\tfov = args.fov\n",
    "\t\tmesh, fov = mesh_reconstruction(input_image, mask, False, fov, args.mask_threshold)\n",
    "\t\tprint(f\"Mesh reconstructed with fov: {fov}\")\n",
    "\t\trender_hint_images(mesh, fov, pls, args.power, output_folder=output_folder, use_gpu=args.use_gpu_for_rendering)\n",
    "\t\tprint(f\"Radiance hints rendered to {output_folder}\")\n",
    "\n",
    "def generate_hints(json_path:str, output_dir:str, gpus = ['0']):\n",
    "\t\t\"\"\"\n",
    "\t\t1. load json file\n",
    "\t\t2. split the (image, mask) pairs into chunks to distribute to GPUs\n",
    "\t\t3. save the chunk to a json file.\n",
    "\t\t4. for each gpu, launch a process to generate hints for the chunk\n",
    "\n",
    "\t\tHow the input json file looks like:\n",
    "\t\t```\n",
    "\t\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\"}\n",
    "\t\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\"}\n",
    "\t\t...\n",
    "\t\t```\n",
    "\t\t\n",
    "\t\tHow the temporary jsonl file looks like:\n",
    "\t\t[\n",
    "\t\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\", viewpoint_id: \"NA6\", lighting_condition_id: '001'}\n",
    "\t\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\", viewpoint_id: \"NA6\", lighting_condition_id: '001'}\n",
    "\t\t...\n",
    "\t\t]\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\t\tjson_path: path to the json file containing the (image, mask) pairs\n",
    "\t\t\t\toutput_dir: path to the output directory\n",
    "\t\t\t\tgpus: list of gpu ids to use for generating hints. e.g. ['0', '1', '2', '3']\n",
    "\t\t\"\"\"\n",
    "\t\twith open(json_path) as f:\n",
    "\t\t\t\tdata = f.readlines()\n",
    "\t\t\n",
    "\t\tif not os.path.exists(output_dir):\n",
    "\t\t\t\tos.makedirs(output_dir, exist_ok=True)\n",
    "\t\t\n",
    "\t\t# split the data into chunks\n",
    "\t\tchunk_size = len(data) // len(gpus)\n",
    "\t\tchunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\t\t\n",
    "\t\tassert len(chunks) == len(gpus)\n",
    "\n",
    "\t\t# save the chunks to jsonl files\n",
    "\t\tfor i, chunk in enumerate(chunks):\n",
    "\t\t\t\tchunk_path = os.path.join(output_dir, f\"chunk_{i}.jsonl\")\n",
    "\t\t\t\twith open(chunk_path, 'w') as f:\n",
    "\t\t\t\t\t\tchunk_json_dicts = []\n",
    "\t\t\t\t\t\tfor line in chunk:\n",
    "\t\t\t\t\t\t\t\timage_path = json.loads(line)['image_path']\n",
    "\t\t\t\t\t\t\t\tmask_path = json.loads(line)['mask_path']\n",
    "\t\t\t\t\t\t\t\tviewpoint_id = image_path.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "\t\t\t\t\t\t\t\tlighting_condition_id = image_path.split('/')[-1].split('_')[-2]\n",
    "\t\t\t\t\t\t\t\tchunk_json_dicts.append({\"image_path\": image_path, \"mask_path\": mask_path, \"viewpoint_id\": viewpoint_id, \"lighting_condition_id\": lighting_condition_id})\n",
    "\t\t\t\t\t\tjson.dump(chunk_json_dicts, f)\n",
    "\t\t\n",
    "\t\t# # generate hints for each chunk\n",
    "\t\t# for i, chunk_path in enumerate(chunks):\n",
    "\t\t# \t\tos.system(f\"CUDA_VISIBLE_DEVICES={gpus[i]} python generate_hint.py --json_path {chunk_path} --output_dir {output_dir}\")\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t\n",
    "\n",
    "\t\t\t\n",
    "\n",
    "\t\t\n",
    "\t\t\n",
    "\n",
    "\t\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_hints('center_cropped_2.jsonl', 'radiance_hints_test', ['0', '1', '2', '3', '4', '5', '6', '7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(img_mask_json_path) as f:\n",
    "\t# load json file as a list of dict\n",
    "\tdata = [json.loads(line) for line in f]\n",
    "\tfor d in tqdm(data):\n",
    "\t\tgenerate_hint(d['image_path'], mask_path=d['mask_path'], output_dir='radiance_hints')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
