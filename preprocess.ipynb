{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "To make a training dataset, we need such things:\n",
    "\n",
    "1. Ground Truth relighted images\n",
    "2. Radiance hints for (1) images\n",
    "3. Provisional Images for (1) images\n",
    "4. generated caption ofr (1) images, using BLIP2 model, for the brightened image.\n",
    "4. jsonl file that contains the information of (1) and (2) images\n",
    "\n",
    "The jsonl file should have the following format:\n",
    "\n",
    "```json\n",
    "{\n",
    "\t\"image\": \"/absolute/path/to/your/file/view_0/white_pl_0/gt.png\",\n",
    "\t\"hint\": [\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_0/gt_diffuse.png\",\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.05.png\"\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.13.png\"\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.34.png\"\n",
    "\t],\n",
    "\t\"ref\": [\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_1/gt.png\",\n",
    "\t\t\"/absolute/path/to/your/file/view_0/env_0/gt.png\",\n",
    "\t\t\"/absolute/path/to/your/file/view_0/env_1/gt.png\",\n",
    "\t\t\"...\"\n",
    "\t],\n",
    "\t\"text\": \"some text description generated by BLIP2\"\n",
    "}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "\n",
    "\n",
    "# DO NOT modify the hyperparameters\n",
    "RESIZE_H, RESIZE_W = 100, 100\n",
    "H, W = 128, 128\n",
    "\n",
    "\n",
    "# Use this function to preprocess data\n",
    "def center_crop_img(tgt_img_path, mask_img_path):\n",
    "\t\"\"\"\n",
    "\tPreprocess the image and mask to center crop and resize to 128x128\n",
    "\n",
    "\tArgs:\n",
    "\t\t\ttgt_img_path (str): Path to the target image\n",
    "\t\t\tmask_img_path (str): Path to the mask image\n",
    "\n",
    "\tReturns:\n",
    "\t\t\t(img_canvas, mask_canvas): Tuple of PIL images\n",
    "\t\"\"\"\n",
    "\ttgt_img = Image.open(tgt_img_path).convert(\"RGB\")\n",
    "\tnp_tgt_img = np.array(tgt_img)\n",
    "\n",
    "\t# mask is processed as [0, 255] value\n",
    "\tmask_img = Image.open(mask_img_path).convert(\"RGB\")  # Foreground mask\n",
    "\t# For some of the masks are given as [0, 255]\n",
    "\tif np.array(mask_img).max() > 1:\n",
    "\t\tnp_mask_img = np.array(mask_img)\n",
    "\telse:\n",
    "\t\tnp_mask_img = np.array(mask_img) * 255\n",
    "\tassert (\n",
    "\t\tnp_mask_img.max() <= 255 and np_mask_img.min() >= 0\n",
    "\t), f\"{np_mask_img.min()}, {np_mask_img.max()}\"\n",
    "\tnp_tgt_img[np_mask_img == 0] = 255\n",
    "\n",
    "\t# Crop image using bbox\n",
    "\ty, x, r = np.where(np_mask_img == 255)  # Get bbox using the mask\n",
    "\tx1, x2, y1, y2 = x.min(), x.max(), y.min(), y.max()\n",
    "\n",
    "\tcrop_img = Image.fromarray(np_tgt_img).crop((x1, y1, x2, y2))\n",
    "\tcropped_mask = Image.fromarray(np_mask_img).crop((x1, y1, x2, y2))\n",
    "\tw = x2 - x1\n",
    "\tassert w > 0, f\"{x2} - {x1} = {w}\"\n",
    "\th = y2 - y1\n",
    "\tassert h > 0, f\"{y2} - {y1} = {h}\"\n",
    "\n",
    "\t# Resize image with respect to max length\n",
    "\tmax_length = max(w, h)\n",
    "\tratio = RESIZE_W / max_length\n",
    "\tresized_w, resized_h = round(w * ratio), round(h * ratio)  # Avoid float error\n",
    "\tassert resized_h == RESIZE_H or resized_w == RESIZE_W\n",
    "\n",
    "\tresized_img = crop_img.resize((resized_w, resized_h))\n",
    "\tresized_object_mask = cropped_mask.resize((resized_w, resized_h))\n",
    "\timg_canvas = Image.new(\"RGB\", (H, W), (255, 255, 255))\n",
    "\tmask_canvas = Image.new(\"RGB\", (H, W), (0, 0, 0))\n",
    "\tpos_w, pos_h = resized_w - W, resized_h - H\n",
    "\n",
    "\tpos_w = abs(pos_w) // 2\n",
    "\tpos_h = abs(pos_h) // 2\n",
    "\tassert pos_w + resized_w <= W and pos_h + resized_h <= H\n",
    "\n",
    "\timg_canvas.paste(resized_img, (pos_w, pos_h))\n",
    "\tmask_canvas.paste(resized_object_mask, (pos_w, pos_h))\n",
    "\n",
    "\treturn img_canvas, mask_canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert object Mask to 3 channel mask.\n",
    "\n",
    "\n",
    "Directory Structure:\n",
    "\n",
    "```plaintext\n",
    "data/\n",
    "\t\timages/\n",
    "\t\t\tobj_28_metal_bucket/\n",
    "\t\t\t\tobj_28_metal_bucket_002_CA2.png\n",
    "\t\t\t\tobj_28_metal_bucket_003_CA2.png  \n",
    "\t\t\t\t...\n",
    "\t\tmasks/\n",
    "\t\t\tobj_28_metal_bucket/\n",
    "\t\t\t\tmask_obj_28_metal_bucket_CA2.png\n",
    "\t\t\t...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# Make jsonl file, which contains the path to the images and masks\n",
    "def make_jsonl(output_path, data_dir):\n",
    "\t\"\"\"\n",
    "\tMake a jsonl file that contains the path to the images and masks.\n",
    "\tThe jsonl file should have the following format:\n",
    "\n",
    "\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\"}\n",
    "\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\"}\n",
    "\n",
    "\tArgs:\n",
    "\t\t\toutput_path (str): path to the output jsonl file.\n",
    "\t\t\tdata_dir (str): path to the data directory.\n",
    "\t\"\"\"\n",
    "\twith open(output_path, \"w\") as f:\n",
    "\t\timages_dir = os.path.join(data_dir, \"images\")\n",
    "\t\tmasks_dir = os.path.join(data_dir, \"masks\")\n",
    "\n",
    "\t\tfor object_name in os.listdir(images_dir):\n",
    "\t\t\tfor image_name in os.listdir(os.path.join(images_dir, object_name)):\n",
    "\t\t\t\timage_path = os.path.join(images_dir, object_name, image_name)\n",
    "\t\t\t\tmask_name = image_name[:-11] + image_name[-7:]\n",
    "\t\t\t\tmask_path = os.path.join(masks_dir, object_name, mask_name)\n",
    "\t\t\t\tf.write(\n",
    "\t\t\t\t\tjson.dumps({\"image_path\": image_path, \"mask_path\": mask_path})\n",
    "\t\t\t\t\t+ \"\\n\"\n",
    "\t\t\t\t)\n",
    "\n",
    "\n",
    "def process_image(k, output_dir, data):\n",
    "\t\"\"\"\n",
    "\tcrop the object image given the mask. and save the cropped image and mask to the output directory.\n",
    "\n",
    "\tArgs:\n",
    "\t\t\tk (str): key of the data.\n",
    "\t\t\toutput_dir (str): output directory.\n",
    "\t\t\tdata (dict): data dictionary. data[k] = {tgt_img_path: str, mask_path: str},\n",
    "\t\t\twhere tgt_img_path is the path to the target image and mask_path is the\n",
    "\t\t\tpath to the mask image.\n",
    "\t\"\"\"\n",
    "\ttgt_img_path = data[k][\"tgt_img_path\"]\n",
    "\tmask_img_path = data[k][\"mask_path\"]\n",
    "\timg, mask = center_crop_img(tgt_img_path, mask_img_path)\n",
    "\n",
    "\timg_name = k + \".png\"\n",
    "\t# key example: 'obj_28_metal_bucket_010_NA3'\n",
    "\tobject_name = k[:-8]\n",
    "\tviewpoint_id = k[-3:]\n",
    "\n",
    "\timage_dir = os.path.join(output_dir, \"images\", object_name)\n",
    "\tif not os.path.exists(image_dir):\n",
    "\t\tos.makedirs(image_dir, exist_ok=True)\n",
    "\toutput_img_path = os.path.join(image_dir, img_name)\n",
    "\n",
    "\tmask_dir = os.path.join(output_dir, \"masks\", object_name)\n",
    "\tif not os.path.exists(mask_dir):\n",
    "\t\tos.makedirs(mask_dir, exist_ok=True)\n",
    "\n",
    "\tmask_file_name = object_name + \"_\" + viewpoint_id + \".png\"\n",
    "\toutput_mask_path = os.path.join(mask_dir, mask_file_name)\n",
    "\n",
    "\timg.save(output_img_path)\n",
    "\tmask.save(output_mask_path)\n",
    "\tprint(f\"Saved {output_img_path}\")\n",
    "\tprint(f\"Saved {output_mask_path}\")\n",
    "\n",
    "\n",
    "# Create a pool of workers\n",
    "def process_images(json_path, output_dir):\n",
    "\t\"\"\"\n",
    "\tProcess all images in the json file and save the cropped images and masks to the output directory.\n",
    "\tAnd make a jsonl file for metadata, named 'img_mask_map.jsonl' in the output directory.\n",
    "\tthe input json file should have the following format:\n",
    "\t{\n",
    "\t\t\t\"obj_1\": {\"tgt_img_path\": \"path/to/target/image\", \"mask_path\": \"path/to/mask/image\"},\n",
    "\t\t\t\"obj_2\": {\"tgt_img_path\": \"path/to/target/image\", \"mask_path\": \"path/to/mask/image\"},\n",
    "\t\t\t...\n",
    "\t}\n",
    "\tArgs:\n",
    "\t\t\tjson_path (str): path to the json file.\n",
    "\t\t\toutput_dir (str): output directory.\n",
    "\t\"\"\"\n",
    "\twith open(json_path) as f:\n",
    "\t\tdata = json.load(f)\n",
    "\tos.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\twith Pool() as pool:\n",
    "\t\tfor _ in tqdm(\n",
    "\t\t\tpool.imap_unordered(\n",
    "\t\t\t\tpartial(process_image, data=data, output_dir=output_dir), data.keys()\n",
    "\t\t\t),\n",
    "\t\t\ttotal=len(data),\n",
    "\t\t):\n",
    "\t\t\tpass\n",
    "\n",
    "\t# make jsonl file for metadata\n",
    "\tmake_jsonl(os.path.join(output_dir, \"img_mask_map.jsonl\"), output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Images and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_file = \"data/metadata.json\"\n",
    "# with open(json_file) as f:\n",
    "# \tdata = json.load(f)\n",
    "# \tprint(len(data))\n",
    "\n",
    "# ouput_dir = \"data/center_cropped_test\"\n",
    "# os.makedirs(ouput_dir, exist_ok=True)\n",
    "\n",
    "# process_images(json_file, \"center_cropped_2_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_mask_json_path = \"data/center_cropped/img_mask_map.jsonl\"\n",
    "# with open(img_mask_json_path) as f:\n",
    "# \tdata = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radiance hints generation\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import json\n",
    "import imageio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import simple_parsing\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "\timg: str  # Path to the image, to generate hints for.\n",
    "\tseed: int = 3407  # Seed for the generation\n",
    "\tfov: Optional[float] = (\n",
    "\t\tNone  # Field of view for the mesh reconstruction, none for auto estimation from the image\n",
    "\t)\n",
    "\n",
    "\tmask_path: Optional[str] = None  # Path to the mask for the image\n",
    "\tuse_sam: bool = True  # Use SAM for background removal\n",
    "\tmask_threshold: float = 25.0  # Mask threshold for foreground object extraction\n",
    "\n",
    "\tpower: float = 1200.0  # Power of the point light\n",
    "\tuse_gpu_for_rendering: bool = True  # Use GPU for radiance hints rendering\n",
    "\n",
    "\tpl_x: float = 1.0  # X position of the point light\n",
    "\tpl_y: float = 1.0  # Y position of the point light\n",
    "\tpl_z: float = 1.0  # Z position of the point light\n",
    "\n",
    "\tenv_map_path: Optional[str] = None  # Path to the environment map\n",
    "\n",
    "# elem function\n",
    "def generate_hint(\n",
    "\timg,\n",
    "\tseed=3407,\n",
    "\tfov=None,\n",
    "\tmask_path=None,\n",
    "\tuse_sam=True,\n",
    "\tmask_threshold=25.0,\n",
    "\tpower=1200.0,\n",
    "\tuse_gpu_for_rendering=True,\n",
    "\tpl_x=1.0,\n",
    "\tpl_y=1.0,\n",
    "\tpl_z=1.0,\n",
    "\toutput_dir=\"radiance_hints\",\n",
    "):\n",
    "\targs = Args(\n",
    "\t\timg=img,\n",
    "\t\tseed=seed,\n",
    "\t\tfov=fov,\n",
    "\t\tmask_path=mask_path,\n",
    "\t\tuse_sam=use_sam,\n",
    "\t\tmask_threshold=mask_threshold,\n",
    "\t\tpower=power,\n",
    "\t\tuse_gpu_for_rendering=use_gpu_for_rendering,\n",
    "\t\tpl_x=pl_x,\n",
    "\t\tpl_y=pl_y,\n",
    "\t\tpl_z=pl_z,\n",
    "\t)\n",
    "\n",
    "\tfrom DiLightNet.demo.mesh_recon import mesh_reconstruction  # depth to mesh\n",
    "\tfrom DiLightNet.demo.render_hints import render_hint_images  # mesh, env_map -> radiance hints\n",
    "\tfrom DiLightNet.demo.rm_bg import rm_bg\n",
    "\n",
    "\t# Load input image and generate/load mask\n",
    "\tinput_image = imageio.v3.imread(args.img)\n",
    "\tinput_image = cv2.resize(input_image, (512, 512))\n",
    "\n",
    "\tif args.mask_path:\n",
    "\t\t# 이건 explicit하게 주면 될듯 하다.\n",
    "\t\tmask = imageio.v3.imread(args.mask_path)\n",
    "\t\tif mask.ndim == 3:\n",
    "\t\t\tmask = mask[..., -1]\n",
    "\t\tmask = cv2.resize(mask, (512, 512))\n",
    "\telse:\n",
    "\t\t_, mask = rm_bg(input_image, use_sam=args.use_sam)\n",
    "\tmask = mask[..., None].repeat(3, axis=-1)\n",
    "\n",
    "\t# Render radiance hints\n",
    "\tpls = [(args.pl_x, args.pl_y, args.pl_z)]\n",
    "\n",
    "\t# cache middle results\n",
    "\t# TODO: lighting condition이 env map에의해서 explicit하게 주어져야 할텐데 약간 걱정되네\n",
    "\timg_id = os.path.basename(args.img).split(\".\")[0]\n",
    "\tlighting_id = f\"pl-{args.pl_x}-{args.pl_y}-{args.pl_z}-{args.power}\"\n",
    "\toutput_folder = os.path.join(output_dir, img_id, lighting_id)\n",
    "\tos.makedirs(output_folder, exist_ok=True)\n",
    "\t# check if the radiance hints are already rendered and full\n",
    "\n",
    "\tprint(f\"Rendering radiance hints\")\n",
    "\t# Mesh reconstruction and fov estimation for hints rendering\n",
    "\tfov = args.fov\n",
    "\t# TODO: explicit하게 mesh를 주면 좋을 것이다. 결과적으로 우리가 할 것은 PSNR을 높히는 것이고, 사용하면 안되는 것은 오직 eval image pairs이다.\n",
    "\tmesh, fov = mesh_reconstruction(input_image, mask, False, fov, args.mask_threshold)\n",
    "\tprint(f\"Mesh reconstructed with fov: {fov}\")\n",
    "\trender_hint_images(\n",
    "\t\tmesh,\n",
    "\t\tfov,\n",
    "\t\tpls,\n",
    "\t\targs.power,\n",
    "\t\toutput_folder=output_folder,\n",
    "\t\tuse_gpu=args.use_gpu_for_rendering,\n",
    "\t)\n",
    "\tprint(f\"Radiance hints rendered to {output_folder}\")\n",
    "\n",
    "# wrapper\n",
    "def generate_hints(json_path: str, output_dir: str, gpus=[\"0\"]):\n",
    "\t\"\"\"\n",
    "\t1. load json file\n",
    "\t2. split the (image, mask) pairs into chunks to distribute to GPUs\n",
    "\t3. save the chunk to a json file.\n",
    "\t4. for each gpu, launch a process to generate hints for the chunk\n",
    "\n",
    "\tHow the input json file looks like:\n",
    "\t```\n",
    "\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\"}\n",
    "\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\"}\n",
    "\t...\n",
    "\t```\n",
    "\n",
    "\tHow the temporary jsonl file looks like:\n",
    "\t[\n",
    "\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\", viewpoint_id: \"NA6\", lighting_condition_id: '001'}\n",
    "\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\", viewpoint_id: \"NA6\", lighting_condition_id: '001'}\n",
    "\t...\n",
    "\t]\n",
    "\n",
    "\tAs a result of running this function, the hints will be saved to the output directory.\n",
    "\tThe output directory will have the following structure:\n",
    "\t```\n",
    "\toutput_dir\n",
    "\t├── chunk_0.jsonl\n",
    "\t├── chunk_1.jsonl\n",
    "\t├── chunk_2.jsonl\n",
    "\t...\n",
    "\t├── chunk_N.jsonl\n",
    "\n",
    "\t├── img_id/\n",
    "\t|   ├── radiance_hint_0.png\n",
    "\t|   ├── radiance_hint_1.png\n",
    "\t|   ├── radiance_hint_2.png\n",
    "\t|   ├── radiance_hint_3.png\n",
    "\t├── img_id/\n",
    "\t|   ├── radiance_hint_0.png\n",
    "\t|   ├── radiance_hint_1.png\n",
    "\t|   ├── radiance_hint_2.png\n",
    "\t|   ├── radiance_hint_3.png\n",
    "\t...\n",
    "\n",
    "\t```\n",
    "\n",
    "\tAnd this function also generates a jsonl file that contains the path to the images and the hints.\n",
    "\tThe jsonl file will have the following format:\n",
    "\t```\n",
    "\t{\"image_id\": \"img_id\", \"object_id\": \"object_id\", \"image_path\": \"path/to/image\",\n",
    "\t  \"mask_path\": \"path/to/mask\", \"radiance_hints_dir\": \"path/to/radiance_hints\"},\n",
    "\t{\"image_id\": \"img_id\", \"object_id\": \"object_id\", \"image_path\": \"path/to/image\",\n",
    "\t  \"mask_path\": \"path/to/mask\", \"radiance_hints_dir\": \"path/to/radiance_hints\"},\n",
    "\t...\n",
    "\t```\n",
    "\n",
    "\tArgs:\n",
    "\t\t\t\t\t\t\t\t\tjson_path: path to the json file containing the (image, mask) pairs\n",
    "\t\t\t\t\t\t\t\t\toutput_dir: path to the output directory\n",
    "\t\t\t\t\t\t\t\t\tgpus: list of gpu ids to use for generating hints. e.g. ['0', '1', '2', '3']\n",
    "\t\"\"\"\n",
    "\twith open(json_path) as f:\n",
    "\t\tdata = f.readlines()\n",
    "\n",
    "\tif not os.path.exists(output_dir):\n",
    "\t\tos.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\t# split the data into chunks\n",
    "\tchunk_size = len(data) // len(gpus)\n",
    "\tchunks = [data[i : i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "\tassert len(chunks) == len(gpus)\n",
    "\n",
    "\t# save the chunks to jsonl files\n",
    "\timage_table = []\n",
    "\tfor i, chunk in enumerate(chunks):\n",
    "\t\tchunk_path = os.path.join(output_dir, f\"chunk_{i}.jsonl\")\n",
    "\t\twith open(chunk_path, \"w\") as f:\n",
    "\t\t\tchunk_json_dicts = []\n",
    "\t\t\tfor line in chunk:\n",
    "\t\t\t\timage_path = json.loads(line)[\"image_path\"]\n",
    "\t\t\t\tmask_path = json.loads(line)[\"mask_path\"]\n",
    "\t\t\t\tviewpoint_id = image_path.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "\t\t\t\tlighting_condition_id = image_path.split(\"/\")[-1].split(\"_\")[-2]\n",
    "\t\t\t\timage_id = image_path.split(\"/\")[-1].split(\".\")[0]\n",
    "\t\t\t\tobject_id = image_path.split(\"/\")[-2]\n",
    "\t\t\t\timage_dict = {\n",
    "\t\t\t\t\t\"image_id\": image_id,\n",
    "\t\t\t\t\t\"object_id\": object_id,\n",
    "\t\t\t\t\t\"image_path\": image_path,\n",
    "\t\t\t\t\t\"mask_path\": mask_path,\n",
    "\t\t\t\t\t\"viewpoint_id\": viewpoint_id,\n",
    "\t\t\t\t\t\"lighting_condition_id\": lighting_condition_id,\n",
    "\t\t\t\t\t\"radiance_hints_dir\": os.path.join(output_dir, image_id),\n",
    "\t\t\t\t}\n",
    "\t\t\t\tchunk_json_dicts.append(image_dict)\n",
    "\t\t\t\timage_table.append(image_dict)\n",
    "\t\t\tjson.dump(chunk_json_dicts, f)\n",
    "\n",
    "\timport subprocess\n",
    "\n",
    "\tprocesses = []\n",
    "\t# generate hints for each chunk, parallelly\n",
    "\tfor i, chunk_path in enumerate(chunks):\n",
    "\t\tcmd = [\n",
    "\t\t\t\"python\",\n",
    "\t\t\t\"generate_hint.py\",\n",
    "\t\t\t\"--json_path\",\n",
    "\t\t\tchunk_path,\n",
    "\t\t\t\"--output_dir\",\n",
    "\t\t\toutput_dir,\n",
    "\t\t]\n",
    "\t\tenv = os.environ.copy()\n",
    "\t\tenv[\"CUDA_VISIBLE_DEVICES\"] = str(gpus[i])  # 각 GPU를 설정\n",
    "\t\tprocess = subprocess.Popen(cmd, env=env)\n",
    "\t\tprocesses.append(process)\n",
    "\n",
    "\t# wait for all processes to finish\n",
    "\tfor process in processes:\n",
    "\t\tprocess.wait()\n",
    "\n",
    "\t# make jsonl file for metadata, using the image_table\n",
    "\twith open(os.path.join(output_dir, \"train_data_metadata.jsonl\"), \"w\") as f:\n",
    "\t\tfor image_dict in image_table:\n",
    "\t\t\tjson.dump(image_dict, f)\n",
    "\t\t\tf.write(\"\\n\")\n",
    "\t# TODO: Need test for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_hints(\n",
    "# \t\"center_cropped_2.jsonl\",\n",
    "# \t\"radiance_hints_test\",\n",
    "# \t[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(img_mask_json_path) as f:\n",
    "# \t# load json file as a list of dict\n",
    "# \tdata = [json.loads(line) for line in f]\n",
    "# \tfor d in tqdm(data):\n",
    "# \t\tgenerate_hint(\n",
    "# \t\t\td[\"image_path\"], mask_path=d[\"mask_path\"], output_dir=\"radiance_hints\"\n",
    "# \t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make train.jsonl\n",
    "\n",
    "```json\n",
    "\n",
    "{\n",
    "\t\"image\": \"/absolute/path/to/your/file/view_0/white_pl_0/gt.png\",\n",
    "\t\"hint\": [\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_0/gt_diffuse.png\",\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.05.png\"\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.13.png\"\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.34.png\"\n",
    "\t],\n",
    "\t\"ref\": [\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_1/gt.png\",\n",
    "\t\t\"/absolute/path/to/your/file/view_0/env_0/gt.png\",\n",
    "\t\t\"/absolute/path/to/your/file/view_0/env_1/gt.png\",\n",
    "\t\t\"...\"\n",
    "\t],\n",
    "\t\"text\": \"some text description generated by BLIP2\"\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "image: 모든 이미지들\n",
    "각 이미지 별로 ref는 다음과 같다.\n",
    "1. 같은 object일 것\n",
    "2. 같은 view일 것\n",
    "3. lighting condition이 다를 것\n",
    "이러면 총 12개의 ref가 나온다.\n",
    "\n",
    "이미지들은 object 별로 정리가 되어 있다. 이미지에 대한 경로 정보는\n",
    "image_mask_map.jsonl 메타데이터 파일에 정리되어 있다.\n",
    "다만 이 파일은 이미지와 마스크에 대한 맵핑만 들고 있지, 오브젝트와 view point, lighting 종류 별로 정리되어 있지 않다.\n",
    "\n",
    "그리고 각 이미지 별로 radiance hint가 4개씩 있는데, 이것에 대한 맵핑도 필요하다.\n",
    "결론적으로 다음 테이블이 있으면 된다.\n",
    "\n",
    "1. image table: image_id, object_id, view_id, light_id, image_path, mask_path, radiance_hint_dir_path\n",
    "\n",
    "위 테이블이 generate_hints() 함수를 실행하면 hint가 들어갈 output_dir에 metadata.jsonl 파일로 생성될 것이다.\n",
    "jsonl파일은 generate_hints() 함수의 documenation을 참고하자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caption generator\n",
    "\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class CaptionGenerator:\n",
    "\tdef __init__(self):\n",
    "\t\t# Use a pipeline as a high-level helper\n",
    "\n",
    "\t\tself.pipe = pipeline(\"image-to-text\", model=\"Salesforce/blip2-opt-2.7b\", device=0)\n",
    "\n",
    "\tdef __call__(self, img_path):\n",
    "\t\tif type(img_path) == str:\n",
    "\t\t\timage = Image.open(img_path).convert(\"RGB\")\n",
    "\t\t\tcaption = self.pipe(image)\n",
    "\t\t\treturn caption[0][\"generated_text\"]\n",
    "\t\telif type(img_path) == list:\n",
    "\t\t\treturn self.batch_process(img_path)\n",
    "\n",
    "\tdef batch_process(self, img_paths):\n",
    "\t\timages = [Image.open(img_path).convert(\"RGB\") for img_path in img_paths]\n",
    "\t\tcaptions = self.pipe(images)\n",
    "\t\treturn [caption[\"generated_text\"] for caption in captions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit Here\n",
    "split = 'train'\n",
    "\n",
    "\n",
    "dataset_dir = f'dataset/{split}'\n",
    "image_dir = os.path.join(dataset_dir, 'images')\n",
    "objects = os.listdir(image_dir)\n",
    "jsons = []\n",
    "for object in tqdm(objects):\n",
    "\tobject_dir = os.path.join(image_dir, object)\n",
    "\timages = os.listdir(object_dir)\n",
    "\tfor image in images:\n",
    "\t\tviewpoint_id = image.split('_')[-1].split('.')[0]\n",
    "\t\tlighting_condition_id = image.split('_')[-2]\n",
    "\t\timage_path = os.path.join(object_dir, image)\n",
    "\t\tmask_path = os.path.join(dataset_dir, 'masks', object, f'{object}_{viewpoint_id}.png')\n",
    "\t\tradiance_hints_dir = os.path.join(dataset_dir, 'hints', object, viewpoint_id, lighting_condition_id)\n",
    "\t\t\n",
    "\t\tjsons.append({\n",
    "\t\t\t\"image_path\": image_path,\n",
    "\t\t\t\"mask_path\": mask_path,\n",
    "\t\t\t\"radiance_hints_dir\": radiance_hints_dir,\n",
    "\t\t\t\"object_id\": object,\n",
    "\t\t\t\"viewpoint_id\": viewpoint_id,\n",
    "\t\t\t\"lighting_condition_id\": lighting_condition_id,\n",
    "\t\t})\n",
    "\n",
    "with open(f'dataset/{split}_data_metadata.jsonl', 'w') as f:\n",
    "\tfor json_dict in jsons:\n",
    "\t\tjson.dump(json_dict, f)\n",
    "\t\tf.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DiLightNet train json generator\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def make_train_jsonl(metadata_jsonl_path: str, output_path: str = \"train_data.jsonl\"):\n",
    "\t\"\"\"\n",
    "\tMake a jsonl file that contains the path to the images and masks and radiance hints.\n",
    "\tThe jsonl file should have the following format:\n",
    "\n",
    "\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\", \"radiance_hints_dir\": \"path/to/radiance_hints\"}\n",
    "\t{\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\", \"radiance_hints_dir\": \"path/to/radiance_hints\"}\n",
    "\twith the follwing keys:\n",
    "\t- image_path: path to the image\n",
    "\t- mask_path: path to the mask\n",
    "\t- radiance_hints_dir: path to the radiance hints directory\n",
    "\t- object_id: object id\n",
    "\t- viewpoint_id: viewpoint id\n",
    "\t- lighting_condition_id: lighting condition id\n",
    "\tArgs:\n",
    "\t\t\tmetadata_jsonl_path (str): path to the metadata jsonl file.\n",
    "\t\t\toutput_path (str): path to the output jsonl file.\n",
    "\t\"\"\"\n",
    "\ttable = pd.read_json(metadata_jsonl_path, lines=True)\n",
    "\tcaption_generator = CaptionGenerator()\n",
    "\ttrain_dicts = []\n",
    "\tnum_rows = len(table)\n",
    "\n",
    "\n",
    "\n",
    "\tfor i, row in tqdm(table.iterrows(), total=num_rows):\n",
    "\t\thint_dir = row[\"radiance_hints_dir\"]\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\thint_images = os.listdir(hint_dir)\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error: {e}\")\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\t# check if the image and masks exists\n",
    "\t\t\tassert os.path.exists(row[\"image_path\"])\n",
    "\t\t\tassert os.path.exists(row[\"mask_path\"])\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error: {e}\")\n",
    "\t\t\tcontinue\n",
    "\t\thint_images = [os.path.join(hint_dir, img) for img in hint_images]\n",
    "\t\tobject_id = row[\"object_id\"]\n",
    "\t\tviewpoint_id = row[\"viewpoint_id\"]\n",
    "\t\tlighting_condition_id = row[\"lighting_condition_id\"]\n",
    "\t\tref_images = []\n",
    "\t\t# 1. find out rows with the same object id and the same viewpoint id\n",
    "\t\tsame_object_rows = table[\n",
    "\t\t\t(table[\"object_id\"] == object_id) & (table[\"viewpoint_id\"] == viewpoint_id)\n",
    "\t\t]\n",
    "\t\t# 2. find out the row with different lighting condition id\n",
    "\t\tfor j, same_object_row in same_object_rows.iterrows():\n",
    "\t\t\tif same_object_row[\"lighting_condition_id\"] != lighting_condition_id:\n",
    "\t\t\t\tref_images.append(same_object_row[\"image_path\"])\n",
    "\n",
    "\t\ttrain_dict = {}\n",
    "\t\ttrain_dict[\"image\"] = row[\"image_path\"]\n",
    "\t\ttrain_dict[\"hint\"] = hint_images\n",
    "\t\ttrain_dict[\"ref\"] = ref_images\n",
    "\t\ttrain_dict[\"text\"] = caption_generator(row[\"image_path\"])\n",
    "\t\ttrain_dicts.append(train_dict)\n",
    "\tdel caption_generator\n",
    "\twith open(output_path, \"w\") as f:\n",
    "\t\tfor train_dict in train_dicts:\n",
    "\t\t\tjson.dump(train_dict, f)\n",
    "\t\t\tf.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_train_jsonl('dataset/eval_data_metadata.jsonl', 'dataset/eval_data.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_json_path = 'dataset/eval_data.jsonl'\n",
    "\n",
    "# load the jsonl as list of dict\n",
    "with open(train_json_path) as f:\n",
    "\ttrain_data = [json.loads(line) for line in f]\n",
    "\n",
    "# add mask path to the dict, to the 'mask' key\n",
    "for data in train_data:\n",
    "\timage_path = data['image']\n",
    "\tobject_id = image_path.split('/')[-2]\n",
    "\tviewpoint_id = image_path.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "\tmask_path = f'dataset/masks/{object_id}/{object_id}_{viewpoint_id}.png'\n",
    "\tdata['mask'] = mask_path\n",
    "\n",
    "# save the updated jsonl\n",
    "with open('dataset/eval_data_with_mask.jsonl', 'w') as f:\n",
    "\tfor data in train_data:\n",
    "\t\tjson.dump(data, f)\n",
    "\t\tf.write('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 폴더 구조 정리\n",
    "\n",
    "```json\n",
    "{\n",
    "\t\"image\": \"dataset/eval/images/obj_28_metal_bucket/obj_28_metal_bucket_006_NC3.png\",\n",
    " \t\"hint\": [\n",
    "\t\t\t\"dataset/eval/hints/obj_28_metal_bucket/NC3/006/hint00_ggx0.13.png\",\n",
    "\t\t\t\"dataset/eval/hints/obj_28_metal_bucket/NC3/006/hint00_ggx0.05.png\",\n",
    "\t\t\t\"dataset/eval/hints/obj_28_metal_bucket/NC3/006/hint00_ggx0.34.png\",\n",
    "\t\t\t\"dataset/eval/hints/obj_28_metal_bucket/NC3/006/hint00_diffuse.png\"],\n",
    "\t\"ref\": [\"dataset/eval/images/obj_28_metal_bucket/obj_28_metal_bucket_011_NC3.png\"], \n",
    "\t\"text\": \"a black bucket with a handle on a white background\\n\",\n",
    "\t\"mask\": \"dataset/masks/obj_28_metal_bucket/obj_28_metal_bucket_NC3.png\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "split = 'eval'\n",
    "dataset_json = f'dataset/{split}_data_with_mask.jsonl'\n",
    "output_dir = f'dataset/{split}_data'\n",
    "resulting_json_dicts = []\n",
    "# read json and hold the data as a list of dict\n",
    "with open(dataset_json) as f:\n",
    "\tdata = [json.loads(line) for line in f]\n",
    "\n",
    "for item in data:\n",
    "\tobject_id = item['image'].split('/')[-2]\n",
    "\tviewpoint_id = item['image'].split('/')[-1].split('_')[-1].split('.')[0]\n",
    "\tlighting_condition_id = item['image'].split('/')[-1].split('_')[-2]\n",
    "\tgt_image_path = item['image']\n",
    "\thints_dir = '/'.join(item['hint'][0].split('/')[:-1])\n",
    "\tgt_diffuse_hint_path = os.path.join(hints_dir, 'hint00_diffuse.png')\n",
    "\tgt_ggx05_hint_path = os.path.join(hints_dir, 'hint00_ggx0.05.png')\n",
    "\tgt_ggx13_hint_path = os.path.join(hints_dir, 'hint00_ggx0.13.png')\n",
    "\tgt_ggx34_hint_path = os.path.join(hints_dir, 'hint00_ggx0.34.png')\n",
    "\thints = [gt_diffuse_hint_path, gt_ggx05_hint_path, gt_ggx13_hint_path, gt_ggx34_hint_path]\n",
    "\t# create the output directory\n",
    "\timage_output_dir = os.path.join(output_dir, object_id, viewpoint_id, lighting_condition_id)\n",
    "\tos.makedirs(image_output_dir, exist_ok=True)\n",
    "\n",
    "\t# copy the images to the output directory\n",
    "\t# output_hint_name =  \n",
    "\t# gt_diffuse.png\n",
    "# │   │   ├── gt_ggx0.34.png\n",
    "# │   │   ├── gt_ggx0.13.png\n",
    "# │   │   ├── gt_ggx0.05.png\n",
    "# │   │   └── gt.png\n",
    "\n",
    "\tdict_json = {}\n",
    "\tdict_json['hint'] = []\n",
    "\tdict_json['ref'] = []\n",
    "\tfor ref in item['ref']:\n",
    "\t\t# copied ref image path\n",
    "\t\tref_object_id = ref.split('/')[-2]\n",
    "\t\tref_viewpoint_id = ref.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "\t\tref_lighting_condition_id = ref.split('/')[-1].split('_')[-2]\n",
    "\t\tref_image_path = os.path.join(output_dir, ref_object_id, ref_viewpoint_id, ref_lighting_condition_id, 'gt.png')\n",
    "\t\tdict_json['ref'].append(ref_image_path)\n",
    "\timport shutil\n",
    "\ttry:\n",
    "\t\tshutil.copy(gt_image_path, os.path.join(image_output_dir, 'gt.png'))\n",
    "\t\tdict_json['image'] = os.path.join(image_output_dir, 'gt.png')\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error: {e}\")\n",
    "\t\n",
    "\ttry:\n",
    "\t\tshutil.copy(gt_diffuse_hint_path, os.path.join(image_output_dir, 'gt_diffuse.png'))\n",
    "\t\tdict_json['hint'].append(os.path.join(image_output_dir, 'gt_diffuse.png'))\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error: {e}\")\n",
    "\t\n",
    "\ttry:\n",
    "\t\tshutil.copy(gt_ggx05_hint_path, os.path.join(image_output_dir, 'gt_ggx0.05.png'))\n",
    "\t\tdict_json['hint'].append(os.path.join(image_output_dir, 'gt_ggx0.05.png'))\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error: {e}\")\n",
    "\t\n",
    "\ttry:\n",
    "\t\tshutil.copy(gt_ggx13_hint_path, os.path.join(image_output_dir, 'gt_ggx0.13.png'))\n",
    "\t\tdict_json['hint'].append(os.path.join(image_output_dir, 'gt_ggx0.13.png'))\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error: {e}\")\n",
    "\t\n",
    "\ttry:\n",
    "\t\tshutil.copy(gt_ggx34_hint_path, os.path.join(image_output_dir, 'gt_ggx0.34.png'))\n",
    "\t\tdict_json['hint'].append(os.path.join(image_output_dir, 'gt_ggx0.34.png'))\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error: {e}\")\n",
    "\n",
    "\tdict_json['text'] = item['text']\n",
    "\tmask_name = f'{object_id}_{viewpoint_id}.png'\n",
    "\tmask_path = os.path.join(output_dir, 'masks', object_id, mask_name)\n",
    "\tdict_json['mask'] = mask_path\n",
    "\tresulting_json_dicts.append(dict_json)\n",
    "\n",
    "\n",
    "# dump json\n",
    "with open(f'dataset/{split}_data_final.jsonl', 'w') as f:\n",
    "\tfor json_dict in resulting_json_dicts:\n",
    "\t\tjson.dump(json_dict, f)\n",
    "\t\tf.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
