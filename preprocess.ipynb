{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "To make a training dataset, we need such things:\n",
    "\n",
    "1. Ground Truth relighted images\n",
    "2. Radiance hints for (1) images\n",
    "3. Provisional Images for (1) images\n",
    "4. generated caption ofr (1) images, using BLIP2 model, for the brightened image.\n",
    "4. jsonl file that contains the information of (1) and (2) images\n",
    "\n",
    "The jsonl file should have the following format:\n",
    "\n",
    "```json\n",
    "{\n",
    "\t\"image\": \"/absolute/path/to/your/file/view_0/white_pl_0/gt.png\",\n",
    "\t\"hint\": [\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_0/gt_diffuse.png\",\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.05.png\"\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.13.png\"\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.34.png\"\n",
    "\t],\n",
    "\t\"ref\": [\n",
    "\t\t\"/absolute/path/to/your/file/view_0/white_pl_1/gt.png\",\n",
    "\t\t\"/absolute/path/to/your/file/view_0/env_0/gt.png\",\n",
    "\t\t\"/absolute/path/to/your/file/view_0/env_1/gt.png\",\n",
    "\t\t\"...\"\n",
    "\t],\n",
    "\t\"text\": \"some text description generated by BLIP2\"\n",
    "}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "\n",
    "\n",
    "# DO NOT modify the hyperparameters\n",
    "RESIZE_H, RESIZE_W = 100, 100\n",
    "H, W = 128, 128\n",
    "\n",
    "\n",
    "# Use this function to preprocess data\n",
    "def center_crop_img(tgt_img_path, mask_img_path):\n",
    "    \"\"\"\n",
    "    Preprocess the image and mask to center crop and resize to 128x128\n",
    "\n",
    "    Args:\n",
    "            tgt_img_path (str): Path to the target image\n",
    "            mask_img_path (str): Path to the mask image\n",
    "\n",
    "    Returns:\n",
    "            (img_canvas, mask_canvas): Tuple of PIL images\n",
    "    \"\"\"\n",
    "    tgt_img = Image.open(tgt_img_path).convert(\"RGB\")\n",
    "    np_tgt_img = np.array(tgt_img)\n",
    "\n",
    "    # mask is processed as [0, 255] value\n",
    "    mask_img = Image.open(mask_img_path).convert(\"RGB\")  # Foreground mask\n",
    "    # For some of the masks are given as [0, 255]\n",
    "    if np.array(mask_img).max() > 1:\n",
    "        np_mask_img = np.array(mask_img)\n",
    "    else:\n",
    "        np_mask_img = np.array(mask_img) * 255\n",
    "    assert (\n",
    "        np_mask_img.max() <= 255 and np_mask_img.min() >= 0\n",
    "    ), f\"{np_mask_img.min()}, {np_mask_img.max()}\"\n",
    "    np_tgt_img[np_mask_img == 0] = 255\n",
    "\n",
    "    # Crop image using bbox\n",
    "    y, x, r = np.where(np_mask_img == 255)  # Get bbox using the mask\n",
    "    x1, x2, y1, y2 = x.min(), x.max(), y.min(), y.max()\n",
    "\n",
    "    crop_img = Image.fromarray(np_tgt_img).crop((x1, y1, x2, y2))\n",
    "    cropped_mask = Image.fromarray(np_mask_img).crop((x1, y1, x2, y2))\n",
    "    w = x2 - x1\n",
    "    assert w > 0, f\"{x2} - {x1} = {w}\"\n",
    "    h = y2 - y1\n",
    "    assert h > 0, f\"{y2} - {y1} = {h}\"\n",
    "\n",
    "    # Resize image with respect to max length\n",
    "    max_length = max(w, h)\n",
    "    ratio = RESIZE_W / max_length\n",
    "    resized_w, resized_h = round(w * ratio), round(h * ratio)  # Avoid float error\n",
    "    assert resized_h == RESIZE_H or resized_w == RESIZE_W\n",
    "\n",
    "    resized_img = crop_img.resize((resized_w, resized_h))\n",
    "    resized_object_mask = cropped_mask.resize((resized_w, resized_h))\n",
    "    img_canvas = Image.new(\"RGB\", (H, W), (255, 255, 255))\n",
    "    mask_canvas = Image.new(\"RGB\", (H, W), (0, 0, 0))\n",
    "    pos_w, pos_h = resized_w - W, resized_h - H\n",
    "\n",
    "    pos_w = abs(pos_w) // 2\n",
    "    pos_h = abs(pos_h) // 2\n",
    "    assert pos_w + resized_w <= W and pos_h + resized_h <= H\n",
    "\n",
    "    img_canvas.paste(resized_img, (pos_w, pos_h))\n",
    "    mask_canvas.paste(resized_object_mask, (pos_w, pos_h))\n",
    "\n",
    "    return img_canvas, mask_canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert object Mask to 3 channel mask.\n",
    "\n",
    "\n",
    "Directory Structure:\n",
    "\n",
    "```plaintext\n",
    "data/\n",
    "\t\timages/\n",
    "\t\t\tobj_28_metal_bucket/\n",
    "\t\t\t\tobj_28_metal_bucket_002_CA2.png\n",
    "\t\t\t\tobj_28_metal_bucket_003_CA2.png  \n",
    "\t\t\t\t...\n",
    "\t\tmasks/\n",
    "\t\t\tobj_28_metal_bucket/\n",
    "\t\t\t\tmask_obj_28_metal_bucket_CA2.png\n",
    "\t\t\t...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# Make jsonl file, which contains the path to the images and masks\n",
    "def make_jsonl(output_path, data_dir):\n",
    "    \"\"\"\n",
    "    Make a jsonl file that contains the path to the images and masks.\n",
    "    The jsonl file should have the following format:\n",
    "\n",
    "    {\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\"}\n",
    "    {\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\"}\n",
    "\n",
    "    Args:\n",
    "            output_path (str): path to the output jsonl file.\n",
    "            data_dir (str): path to the data directory.\n",
    "    \"\"\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        images_dir = os.path.join(data_dir, \"images\")\n",
    "        masks_dir = os.path.join(data_dir, \"masks\")\n",
    "\n",
    "        for object_name in os.listdir(images_dir):\n",
    "            for image_name in os.listdir(os.path.join(images_dir, object_name)):\n",
    "                image_path = os.path.join(images_dir, object_name, image_name)\n",
    "                mask_name = image_name[:-11] + image_name[-7:]\n",
    "                mask_path = os.path.join(masks_dir, object_name, mask_name)\n",
    "                f.write(\n",
    "                    json.dumps({\"image_path\": image_path, \"mask_path\": mask_path})\n",
    "                    + \"\\n\"\n",
    "                )\n",
    "\n",
    "\n",
    "def process_image(k, output_dir, data):\n",
    "    \"\"\"\n",
    "    crop the object image given the mask. and save the cropped image and mask to the output directory.\n",
    "\n",
    "    Args:\n",
    "            k (str): key of the data.\n",
    "            output_dir (str): output directory.\n",
    "            data (dict): data dictionary. data[k] = {tgt_img_path: str, mask_path: str},\n",
    "            where tgt_img_path is the path to the target image and mask_path is the\n",
    "            path to the mask image.\n",
    "    \"\"\"\n",
    "    tgt_img_path = data[k][\"tgt_img_path\"]\n",
    "    mask_img_path = data[k][\"mask_path\"]\n",
    "    img, mask = center_crop_img(tgt_img_path, mask_img_path)\n",
    "\n",
    "    img_name = k + \".png\"\n",
    "    # key example: 'obj_28_metal_bucket_010_NA3'\n",
    "    object_name = k[:-8]\n",
    "    viewpoint_id = k[-3:]\n",
    "\n",
    "    image_dir = os.path.join(output_dir, \"images\", object_name)\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "    output_img_path = os.path.join(image_dir, img_name)\n",
    "\n",
    "    mask_dir = os.path.join(output_dir, \"masks\", object_name)\n",
    "    if not os.path.exists(mask_dir):\n",
    "        os.makedirs(mask_dir, exist_ok=True)\n",
    "\n",
    "    mask_file_name = object_name + \"_\" + viewpoint_id + \".png\"\n",
    "    output_mask_path = os.path.join(mask_dir, mask_file_name)\n",
    "\n",
    "    img.save(output_img_path)\n",
    "    mask.save(output_mask_path)\n",
    "    print(f\"Saved {output_img_path}\")\n",
    "    print(f\"Saved {output_mask_path}\")\n",
    "\n",
    "\n",
    "# Create a pool of workers\n",
    "def process_images(json_path, output_dir):\n",
    "    \"\"\"\n",
    "    Process all images in the json file and save the cropped images and masks to the output directory.\n",
    "    And make a jsonl file for metadata, named 'img_mask_map.jsonl' in the output directory.\n",
    "    the input json file should have the following format:\n",
    "    {\n",
    "            \"obj_1\": {\"tgt_img_path\": \"path/to/target/image\", \"mask_path\": \"path/to/mask/image\"},\n",
    "            \"obj_2\": {\"tgt_img_path\": \"path/to/target/image\", \"mask_path\": \"path/to/mask/image\"},\n",
    "            ...\n",
    "    }\n",
    "    Args:\n",
    "            json_path (str): path to the json file.\n",
    "            output_dir (str): output directory.\n",
    "    \"\"\"\n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with Pool() as pool:\n",
    "        for _ in tqdm(\n",
    "            pool.imap_unordered(\n",
    "                partial(process_image, data=data, output_dir=output_dir), data.keys()\n",
    "            ),\n",
    "            total=len(data),\n",
    "        ):\n",
    "            pass\n",
    "\n",
    "    # make jsonl file for metadata\n",
    "    make_jsonl(os.path.join(output_dir, \"img_mask_map.jsonl\"), output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Images and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/metadata.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m json_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/metadata.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/metadata.json'"
     ]
    }
   ],
   "source": [
    "json_file = \"data/metadata.json\"\n",
    "with open(json_file) as f:\n",
    "    data = json.load(f)\n",
    "    print(len(data))\n",
    "\n",
    "ouput_dir = \"data/center_cropped_test\"\n",
    "os.makedirs(ouput_dir, exist_ok=True)\n",
    "\n",
    "process_images(json_file, \"center_cropped_2_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask_json_path = \"data/center_cropped/img_mask_map.jsonl\"\n",
    "with open(img_mask_json_path) as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radiance hints generation\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import json\n",
    "import imageio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import simple_parsing\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    img: str  # Path to the image, to generate hints for.\n",
    "    seed: int = 3407  # Seed for the generation\n",
    "    fov: Optional[float] = (\n",
    "        None  # Field of view for the mesh reconstruction, none for auto estimation from the image\n",
    "    )\n",
    "\n",
    "    mask_path: Optional[str] = None  # Path to the mask for the image\n",
    "    use_sam: bool = True  # Use SAM for background removal\n",
    "    mask_threshold: float = 25.0  # Mask threshold for foreground object extraction\n",
    "\n",
    "    power: float = 1200.0  # Power of the point light\n",
    "    use_gpu_for_rendering: bool = True  # Use GPU for radiance hints rendering\n",
    "\n",
    "    pl_x: float = 1.0  # X position of the point light\n",
    "    pl_y: float = 1.0  # Y position of the point light\n",
    "    pl_z: float = 1.0  # Z position of the point light\n",
    "\n",
    "    env_map_path: Optional[str] = None  # Path to the environment map\n",
    "\n",
    "# elem function\n",
    "def generate_hint(\n",
    "    img,\n",
    "    seed=3407,\n",
    "    fov=None,\n",
    "    mask_path=None,\n",
    "    use_sam=True,\n",
    "    mask_threshold=25.0,\n",
    "    power=1200.0,\n",
    "    use_gpu_for_rendering=True,\n",
    "    pl_x=1.0,\n",
    "    pl_y=1.0,\n",
    "    pl_z=1.0,\n",
    "    output_dir=\"radiance_hints\",\n",
    "):\n",
    "    args = Args(\n",
    "        img=img,\n",
    "        seed=seed,\n",
    "        fov=fov,\n",
    "        mask_path=mask_path,\n",
    "        use_sam=use_sam,\n",
    "        mask_threshold=mask_threshold,\n",
    "        power=power,\n",
    "        use_gpu_for_rendering=use_gpu_for_rendering,\n",
    "        pl_x=pl_x,\n",
    "        pl_y=pl_y,\n",
    "        pl_z=pl_z,\n",
    "    )\n",
    "\n",
    "    from DiLightNet.demo.mesh_recon import mesh_reconstruction  # depth to mesh\n",
    "    from DiLightNet.demo.render_hints import render_hint_images  # mesh, env_map -> radiance hints\n",
    "    from DiLightNet.demo.rm_bg import rm_bg\n",
    "\n",
    "    # Load input image and generate/load mask\n",
    "    input_image = imageio.v3.imread(args.img)\n",
    "    input_image = cv2.resize(input_image, (512, 512))\n",
    "\n",
    "    if args.mask_path:\n",
    "        # 이건 explicit하게 주면 될듯 하다.\n",
    "        mask = imageio.v3.imread(args.mask_path)\n",
    "        if mask.ndim == 3:\n",
    "            mask = mask[..., -1]\n",
    "        mask = cv2.resize(mask, (512, 512))\n",
    "    else:\n",
    "        _, mask = rm_bg(input_image, use_sam=args.use_sam)\n",
    "    mask = mask[..., None].repeat(3, axis=-1)\n",
    "\n",
    "    # Render radiance hints\n",
    "    pls = [(args.pl_x, args.pl_y, args.pl_z)]\n",
    "\n",
    "    # cache middle results\n",
    "    # TODO: lighting condition이 env map에의해서 explicit하게 주어져야 할텐데 약간 걱정되네\n",
    "    img_id = os.path.basename(args.img).split(\".\")[0]\n",
    "    lighting_id = f\"pl-{args.pl_x}-{args.pl_y}-{args.pl_z}-{args.power}\"\n",
    "    output_folder = os.path.join(output_dir, img_id, lighting_id)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    # check if the radiance hints are already rendered and full\n",
    "\n",
    "    print(f\"Rendering radiance hints\")\n",
    "    # Mesh reconstruction and fov estimation for hints rendering\n",
    "    fov = args.fov\n",
    "    # TODO: explicit하게 mesh를 주면 좋을 것이다. 결과적으로 우리가 할 것은 PSNR을 높히는 것이고, 사용하면 안되는 것은 오직 eval image pairs이다.\n",
    "    mesh, fov = mesh_reconstruction(input_image, mask, False, fov, args.mask_threshold)\n",
    "    print(f\"Mesh reconstructed with fov: {fov}\")\n",
    "    render_hint_images(\n",
    "        mesh,\n",
    "        fov,\n",
    "        pls,\n",
    "        args.power,\n",
    "        output_folder=output_folder,\n",
    "        use_gpu=args.use_gpu_for_rendering,\n",
    "    )\n",
    "    print(f\"Radiance hints rendered to {output_folder}\")\n",
    "\n",
    "# wrapper\n",
    "def generate_hints(json_path: str, output_dir: str, gpus=[\"0\"]):\n",
    "    \"\"\"\n",
    "    1. load json file\n",
    "    2. split the (image, mask) pairs into chunks to distribute to GPUs\n",
    "    3. save the chunk to a json file.\n",
    "    4. for each gpu, launch a process to generate hints for the chunk\n",
    "\n",
    "    How the input json file looks like:\n",
    "    ```\n",
    "    {\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\"}\n",
    "    {\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\"}\n",
    "    ...\n",
    "    ```\n",
    "\n",
    "    How the temporary jsonl file looks like:\n",
    "    [\n",
    "    {\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\", viewpoint_id: \"NA6\", lighting_condition_id: '001'}\n",
    "    {\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\", viewpoint_id: \"NA6\", lighting_condition_id: '001'}\n",
    "    ...\n",
    "    ]\n",
    "\n",
    "    As a result of running this function, the hints will be saved to the output directory.\n",
    "    The output directory will have the following structure:\n",
    "    ```\n",
    "    output_dir\n",
    "    ├── chunk_0.jsonl\n",
    "    ├── chunk_1.jsonl\n",
    "    ├── chunk_2.jsonl\n",
    "    ...\n",
    "    ├── chunk_N.jsonl\n",
    "\n",
    "    ├── img_id/\n",
    "    |   ├── radiance_hint_0.png\n",
    "    |   ├── radiance_hint_1.png\n",
    "    |   ├── radiance_hint_2.png\n",
    "    |   ├── radiance_hint_3.png\n",
    "    ├── img_id/\n",
    "    |   ├── radiance_hint_0.png\n",
    "    |   ├── radiance_hint_1.png\n",
    "    |   ├── radiance_hint_2.png\n",
    "    |   ├── radiance_hint_3.png\n",
    "    ...\n",
    "\n",
    "    ```\n",
    "\n",
    "    And this function also generates a jsonl file that contains the path to the images and the hints.\n",
    "    The jsonl file will have the following format:\n",
    "    ```\n",
    "    {\"image_id\": \"img_id\", \"object_id\": \"object_id\", \"image_path\": \"path/to/image\",\n",
    "      \"mask_path\": \"path/to/mask\", \"radiance_hints_dir\": \"path/to/radiance_hints\"},\n",
    "    {\"image_id\": \"img_id\", \"object_id\": \"object_id\", \"image_path\": \"path/to/image\",\n",
    "      \"mask_path\": \"path/to/mask\", \"radiance_hints_dir\": \"path/to/radiance_hints\"},\n",
    "    ...\n",
    "    ```\n",
    "\n",
    "    Args:\n",
    "                                    json_path: path to the json file containing the (image, mask) pairs\n",
    "                                    output_dir: path to the output directory\n",
    "                                    gpus: list of gpu ids to use for generating hints. e.g. ['0', '1', '2', '3']\n",
    "    \"\"\"\n",
    "    with open(json_path) as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # split the data into chunks\n",
    "    chunk_size = len(data) // len(gpus)\n",
    "    chunks = [data[i : i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "    assert len(chunks) == len(gpus)\n",
    "\n",
    "    # save the chunks to jsonl files\n",
    "    image_table = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_path = os.path.join(output_dir, f\"chunk_{i}.jsonl\")\n",
    "        with open(chunk_path, \"w\") as f:\n",
    "            chunk_json_dicts = []\n",
    "            for line in chunk:\n",
    "                image_path = json.loads(line)[\"image_path\"]\n",
    "                mask_path = json.loads(line)[\"mask_path\"]\n",
    "                viewpoint_id = image_path.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "                lighting_condition_id = image_path.split(\"/\")[-1].split(\"_\")[-2]\n",
    "                image_id = image_path.split(\"/\")[-1].split(\".\")[0]\n",
    "                object_id = image_path.split(\"/\")[-2]\n",
    "                image_dict = {\n",
    "                    \"image_id\": image_id,\n",
    "                    \"object_id\": object_id,\n",
    "                    \"image_path\": image_path,\n",
    "                    \"mask_path\": mask_path,\n",
    "                    \"viewpoint_id\": viewpoint_id,\n",
    "                    \"lighting_condition_id\": lighting_condition_id,\n",
    "                    \"radiance_hints_dir\": os.path.join(output_dir, image_id),\n",
    "                }\n",
    "                chunk_json_dicts.append(image_dict)\n",
    "                image_table.append(image_dict)\n",
    "            json.dump(chunk_json_dicts, f)\n",
    "\n",
    "    import subprocess\n",
    "\n",
    "    processes = []\n",
    "    # generate hints for each chunk, parallelly\n",
    "    for i, chunk_path in enumerate(chunks):\n",
    "        cmd = [\n",
    "            \"python\",\n",
    "            \"generate_hint.py\",\n",
    "            \"--json_path\",\n",
    "            chunk_path,\n",
    "            \"--output_dir\",\n",
    "            output_dir,\n",
    "        ]\n",
    "        env = os.environ.copy()\n",
    "        env[\"CUDA_VISIBLE_DEVICES\"] = str(gpus[i])  # 각 GPU를 설정\n",
    "        process = subprocess.Popen(cmd, env=env)\n",
    "        processes.append(process)\n",
    "\n",
    "    # wait for all processes to finish\n",
    "    for process in processes:\n",
    "        process.wait()\n",
    "\n",
    "    # make jsonl file for metadata, using the image_table\n",
    "    with open(os.path.join(output_dir, \"train_data_metadata.jsonl\"), \"w\") as f:\n",
    "        for image_dict in image_table:\n",
    "            json.dump(image_dict, f)\n",
    "            f.write(\"\\n\")\n",
    "    # TODO: Need test for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_hints(\n",
    "    \"center_cropped_2.jsonl\",\n",
    "    \"radiance_hints_test\",\n",
    "    [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(img_mask_json_path) as f:\n",
    "    # load json file as a list of dict\n",
    "    data = [json.loads(line) for line in f]\n",
    "    for d in tqdm(data):\n",
    "        generate_hint(\n",
    "            d[\"image_path\"], mask_path=d[\"mask_path\"], output_dir=\"radiance_hints\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make train.jsonl\n",
    "\n",
    "```json\n",
    "\n",
    "{\n",
    "  \"image\": \"/absolute/path/to/your/file/view_0/white_pl_0/gt.png\",\n",
    "  \"hint\": [\n",
    "    \"/absolute/path/to/your/file/view_0/white_pl_0/gt_diffuse.png\",\n",
    "    \"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.05.png\"\n",
    "    \"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.13.png\"\n",
    "    \"/absolute/path/to/your/file/view_0/white_pl_0/gt_ggx0.34.png\"\n",
    "  ],\n",
    "  \"ref\": [\n",
    "    \"/absolute/path/to/your/file/view_0/white_pl_1/gt.png\",\n",
    "    \"/absolute/path/to/your/file/view_0/env_0/gt.png\",\n",
    "    \"/absolute/path/to/your/file/view_0/env_1/gt.png\",\n",
    "    \"...\"\n",
    "  ],\n",
    "  \"text\": \"some text description generated by BLIP2\"\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "image: 모든 이미지들\n",
    "각 이미지 별로 ref는 다음과 같다.\n",
    "1. 같은 object일 것\n",
    "2. 같은 view일 것\n",
    "3. lighting condition이 다를 것\n",
    "이러면 총 12개의 ref가 나온다.\n",
    "\n",
    "이미지들은 object 별로 정리가 되어 있다. 이미지에 대한 경로 정보는\n",
    "image_mask_map.jsonl 메타데이터 파일에 정리되어 있다.\n",
    "다만 이 파일은 이미지와 마스크에 대한 맵핑만 들고 있지, 오브젝트와 view point, lighting 종류 별로 정리되어 있지 않다.\n",
    "\n",
    "그리고 각 이미지 별로 radiance hint가 4개씩 있는데, 이것에 대한 맵핑도 필요하다.\n",
    "결론적으로 다음 테이블이 있으면 된다.\n",
    "\n",
    "1. image table: image_id, object_id, view_id, light_id, image_path, mask_path, radiance_hint_dir_path\n",
    "\n",
    "위 테이블이 generate_hints() 함수를 실행하면 hint가 들어갈 output_dir에 metadata.jsonl 파일로 생성될 것이다.\n",
    "jsonl파일은 generate_hints() 함수의 documenation을 참고하자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caption generator\n",
    "\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class CaptionGenerator:\n",
    "    def __init__(self):\n",
    "        # Use a pipeline as a high-level helper\n",
    "\n",
    "        self.pipe = pipeline(\"image-to-text\", model=\"Salesforce/blip2-opt-2.7b\")\n",
    "\n",
    "    def __call__(self, img_path):\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        caption = self.pipe(image)\n",
    "        return caption[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/root/project/data/center_cropped/images/obj_01_car/obj_01_car_001_CA2.png'\n",
    "caption_generator = CaptionGenerator()\n",
    "caption = caption_generator(image_path)\n",
    "print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DiLightNet train json generator\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def make_train_jsonl(metadata_jsonl_path: str, output_path: str = \"train_data.jsonl\"):\n",
    "    \"\"\"\n",
    "    Make a jsonl file that contains the path to the images and masks and radiance hints.\n",
    "    The jsonl file should have the following format:\n",
    "\n",
    "    {\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\", \"radiance_hints_dir\": \"path/to/radiance_hints\"}\n",
    "    {\"image_path\": \"path/to/image\", \"mask_path\": \"path/to/mask\", \"radiance_hints_dir\": \"path/to/radiance_hints\"}\n",
    "\n",
    "    Args:\n",
    "            metadata_jsonl_path (str): path to the metadata jsonl file.\n",
    "            output_path (str): path to the output jsonl file.\n",
    "    \"\"\"\n",
    "    table = pd.read_json(metadata_jsonl_path, lines=True)\n",
    "    caption_generator = CaptionGenerator()\n",
    "    train_dicts = []\n",
    "    for i, row in table.iterrows():\n",
    "        hint_dir = row[\"radiance_hints_dir\"]\n",
    "        hint_images = os.listdir(hint_dir)\n",
    "        hint_images = [os.path.join(hint_dir, img) for img in hint_images]\n",
    "        object_id = row[\"object_id\"]\n",
    "        viewpoint_id = row[\"viewpoint_id\"]\n",
    "        lighting_condition_id = row[\"lighting_condition_id\"]\n",
    "        ref_images = []\n",
    "        # 1. find out rows with the same object id and the same viewpoint id\n",
    "        same_object_rows = table[\n",
    "            (table[\"object_id\"] == object_id) & (table[\"viewpoint_id\"] == viewpoint_id)\n",
    "        ]\n",
    "        # 2. find out the row with different lighting condition id\n",
    "        for j, same_object_row in same_object_rows.iterrows():\n",
    "            if same_object_row[\"lighting_condition_id\"] != lighting_condition_id:\n",
    "                ref_images.append(same_object_row[\"image_path\"])\n",
    "\n",
    "        train_dict = {}\n",
    "        train_dict[\"image\"] = row[\"image_path\"]\n",
    "        train_dict[\"hint\"] = hint_images\n",
    "        train_dict[\"ref\"] = ref_images\n",
    "        train_dict[\"text\"] = caption_generator(row[\"image_path\"])\n",
    "        train_dicts.append(train_dict)\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        for train_dict in train_dicts:\n",
    "            json.dump(train_dict, f)\n",
    "            f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
